{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9984c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d3ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from typing import DefaultDict, List\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"./hf_transformers\")\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Tokenizer\n",
    "from transformers import set_seed\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from data_reader import DataPoint, GetDataAsPython, MinimalDataPoint\n",
    "from prepare_data import create_data_tbug\n",
    "from prepare_data import create_dataset\n",
    "from prepare_data import extract_warning_types\n",
    "from prepare_data import filter_rule\n",
    "from utils import boolean_string\n",
    "from utils import get_scores_weighted_average\n",
    "from utils import get_current_time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18db93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b7212b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "local = False if 'computecanada' in socket.gethostname() else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c58e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local:\n",
    "    storage_directory = './storage/'\n",
    "else:\n",
    "    storage_directory = '/scratch/arminz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db5f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 't5-small' # args.model_name\n",
    "result_dir = '' #args.result_dir\n",
    "repo = None #args.repo\n",
    "design = 'repo-based-included' #args.design\n",
    "error_type = '' #args.error_type\n",
    "load_model = f'{storage_directory}/training-tbug/t5-small_repo-based_29-04-2022_09-38-17/checkpoint-14235' #args.load_model\n",
    "batch_size = 16 #args.batch_size\n",
    "eval_acc_steps = 1 # eval-acc-steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a27905",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "# Create job's directory\n",
    "if result_dir != \"\":\n",
    "    test_result_directory = args.result_dir\n",
    "else:\n",
    "    if not repo:\n",
    "        test_result_directory = f'{storage_directory}/testing-tbug/{now.day}/general_{model_name}_test_{design}_{dt_string}'\n",
    "    else:\n",
    "        test_result_directory = f'{storage_directory}/testing-tbug/{now.day}/per-repo/{model_name}_test_{repo.rsplit(\"/\", 1)[1][-20:]}_{dt_string}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb95d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GetDataAsPython(f\"{storage_directory}/data_and_models/data/data_autofix_tracking_repo_specific_final.json\")\n",
    "data_eslint = GetDataAsPython(f\"{storage_directory}/data_and_models/data/data_autofix_tracking_eslint_final.json\")\n",
    "data += data_eslint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f95a37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_warning_types = extract_warning_types(data)\n",
    "if error_type != \"\":\n",
    "    all_warning_types = [error_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20c90cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting by : repo-based-included\n",
      "train size: 52\n",
      "test size: 3374\n"
     ]
    }
   ],
   "source": [
    "(train_inputs, train_labels, test_inputs, test_labels, train_info, test_info, ) =\\\n",
    "    create_data_tbug(data, all_warning_types, include_warning=True, design=design, select_repo=repo, back_translation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6eaa1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from directory ./storage//training-tbug/t5-small_repo-based_29-04-2022_09-38-17/checkpoint-14235\n",
      "Loaded model from directory ./storage//training-tbug/t5-small_repo-based_29-04-2022_09-38-17/checkpoint-14235\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32104, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32104, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32104, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32104, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the tokenizer and the model that will be tested.\n",
    "tokenizer = T5Tokenizer.from_pretrained(f'{load_model}')\n",
    "print(\"Loaded tokenizer from directory {}\".format(f'{load_model}'))\n",
    "model = T5ForConditionalGeneration.from_pretrained(f'{load_model}')\n",
    "print(\"Loaded model from directory {}\".format(f'{load_model}'))\n",
    "print(f\"cuda:{torch.cuda.current_device()}\")\n",
    "model.to(f\"cuda:{torch.cuda.current_device()}\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87aa86ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armin/TFix/env/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:185: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = create_dataset(\n",
    "    train_labels['no-invalid-this'], train_inputs['no-invalid-this'], tokenizer, pad_truncate=True, max_length=128\n",
    ")\n",
    "# val_dataset = create_dataset(val_labels, val_inputs, tokenizer, pad_truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d501e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c7d4c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"fix no-invalid-this Unexpected 'this'. \\treturn Math.min(0, this.imageHeight - this.scaledRotatedInternalImageHeight);\\n:\\nexport default function() {\\n\\treturn Math.min(0, this.imageHeight - this.scaledRotatedInternalImageHeight);\\n}\\n </s>\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs['no-invalid-this'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c94b2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bug no-invalid-this Unexpected 'this'. export default function() {\\n\\treturn Math.min(0, this.scaledRotatedInternalImageHeightDifference);\\n}\\n </s>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels['no-invalid-this'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c04d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=test_result_directory,\n",
    "    num_train_epochs=0,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_dir=test_result_directory,\n",
    "    logging_steps=100,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    eval_accumulation_steps=eval_acc_steps,  # set this lower, if testing or validation crashes\n",
    "    predict_with_generate=True,  # never set this to false, it is for testing.\n",
    "    seed=42,  # default value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64db6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e511325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  101430\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for key in train_inputs:\n",
    "    counter += len(train_inputs[key])\n",
    "print(\"Number of training samples: \", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c3bb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "for warning in test_inputs:\n",
    "    inputs = train_inputs[warning] #test_inputs[warning]\n",
    "    infos = train_info[warning] #test_info[warning]\n",
    "    for i, code in enumerate(inputs):\n",
    "        assert code == infos[i].GetT5Representation(True)[0], \"something wrong! stop it!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de8484f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_repos = '/data/all/data/qooxdoo/qooxdoo','/data/all/data/elastic/kibana','/data/all/data/emberjs/ember.js','/data/all/data/zloirock/core-js','/data/all/data/Encapsule-Annex/onm','/data/all/data/sequelize/sequelize','/data/all/data/dcos/dcos-ui','/data/all/data/LivelyKernel/LivelyKernel','/data/all/data/svgdotjs/svg.js','/data/all/data/foam-framework/foam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc02a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='136' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 05:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 0 (no-invalid-this) acc: 0.02, 161\n",
      "rule 1 (no-throw-literal) acc: 0.91, 174\n",
      "rule 2 (no-new-wrappers) acc: 0.33, 3\n",
      "rule 3 (guard-for-in) acc: 0.15, 20\n",
      "rule 5 (comma-style) acc: 0.22, 308\n",
      "rule 6 (prefer-spread) acc: 0.66, 86\n",
      "rule 7 (no-caller) acc: 0.05, 19\n",
      "rule 8 (no-extra-bind) acc: 0.00, 2\n",
      "rule 9 (no-array-constructor) acc: 0.00, 1\n",
      "rule 10 (prefer-rest-params) acc: 0.62, 155\n",
      "rule 13 (no-extend-native) acc: 0.42, 24\n",
      "rule 14 (no-undef) acc: 0.03, 129\n",
      "rule 15 (no-useless-escape) acc: 0.00, 11\n",
      "rule 16 (no-dupe-keys) acc: 0.26, 34\n",
      "rule 17 (no-console) acc: 0.17, 12\n",
      "rule 18 (no-constant-condition) acc: 0.00, 12\n",
      "rule 19 (no-duplicate-case) acc: 0.50, 2\n",
      "rule 20 (no-empty) acc: 0.55, 11\n",
      "rule 21 (no-extra-semi) acc: 0.75, 244\n",
      "rule 22 (no-redeclare) acc: 0.29, 45\n",
      "rule 23 (no-cond-assign) acc: 0.30, 10\n",
      "rule 24 (no-extra-boolean-cast) acc: 0.55, 20\n",
      "rule 26 (no-unreachable) acc: 0.28, 18\n",
      "rule 27 (valid-typeof) acc: 0.00, 1\n",
      "rule 28 (no-unsafe-finally) acc: 0.00, 1\n",
      "rule 29 (no-unused-vars) acc: 0.00, 62\n",
      "rule 30 (no-debugger) acc: 0.56, 117\n",
      "rule 31 (no-unsafe-negation) acc: 0.00, 2\n",
      "rule 32 (no-case-declarations) acc: 1.00, 1\n",
      "rule 33 (no-self-assign) acc: 1.00, 2\n",
      "rule 34 (no-process-exit) acc: 1.00, 2\n",
      "rule 35 (no-inner-declarations) acc: 0.50, 4\n",
      "rule 36 (for-direction) acc: 0.00, 1\n",
      "rule 39 (no-func-assign) acc: 0.50, 2\n",
      "rule 41 (no-global-assign) acc: 0.00, 8\n",
      "rule 42 (use-isnan) acc: 0.00, 1\n",
      "rule 43 (no-unused-labels) acc: 0.00, 1\n",
      "rule 45 (getter-return) acc: 0.00, 1\n",
      "rule 48 (constructor-super) acc: 0.00, 1\n",
      "rule 49 (no-new-symbol) acc: 0.00, 1\n",
      "rule 50 (no-empty-pattern) acc: 0.00, 1\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "scores: DefaultDict[str, float] = defaultdict(float)\n",
    "counts: DefaultDict[str, float] = defaultdict(int)\n",
    "for i, warning in enumerate(all_warning_types):\n",
    "    test_warning = [] #test_inputs[warning]\n",
    "    test_warning_labels = [] #test_labels[warning]\n",
    "    test_warning_info = [] #train_info[warning] #test_info[warning]\n",
    "    \n",
    "    for input_, label_, info_ in zip(train_inputs[warning], train_labels[warning], train_info[warning]):\n",
    "        if info_.repo not in da_repos:\n",
    "            continue\n",
    "        test_warning.append(input_)\n",
    "        test_warning_labels.append(label_)\n",
    "        test_warning_info.append(info_)\n",
    "        \n",
    "    target_max_length = 256  # Set this to 256 if enough memory\n",
    "    if not test_warning_labels:\n",
    "        scores[warning] = 'NA'\n",
    "        counts[warning] = 0\n",
    "        continue\n",
    "    # print(f\"rule {i}: {warning}, # {len(test_warning)}\")\n",
    "    test_warning_dataset = create_dataset(\n",
    "        test_warning_labels,\n",
    "        test_warning,\n",
    "        tokenizer,\n",
    "        pad_truncate=True,\n",
    "        max_length=target_max_length,\n",
    "    )\n",
    "\n",
    "    target_ids = tokenizer(\n",
    "        test_warning,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=target_max_length,\n",
    "    ).input_ids\n",
    "    target_ids = np.array(target_ids)\n",
    "\n",
    "    output_ids = trainer.predict(\n",
    "        test_dataset=test_warning_dataset, num_beams=5, max_length=target_max_length\n",
    "    ).predictions\n",
    "    output_ids = np.pad(\n",
    "        output_ids, ((0, 0), (0, target_max_length - output_ids.shape[1])), mode=\"constant\"\n",
    "    )\n",
    "    output_ids = np.delete(output_ids, 0, axis=1)\n",
    "    output_ids = np.insert(output_ids, target_max_length - 1, 0, axis=1)\n",
    "\n",
    "    correct_counter = np.sum(np.all(np.equal(target_ids, output_ids), axis=1))\n",
    "    total_counter = len(output_ids)\n",
    "    for k, output_id in enumerate(output_ids):\n",
    "        pred = tokenizer.decode(output_id, skip_special_tokens=True)\n",
    "        predictions = []\n",
    "        predictions.append(pred)\n",
    "        test_warning_info[k].predictions = predictions\n",
    "\n",
    "    scores[warning] = correct_counter / total_counter\n",
    "    counts[warning] = total_counter\n",
    "    test_info[warning] = test_warning_info\n",
    "    print(f\"rule {i} ({warning}) acc: {correct_counter / total_counter:.2f}, {total_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ac4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34a21f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{storage_directory}/bt_data/scores.json', 'w') as f:\n",
    "    json.dump(scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b898da43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOMklEQVR4nO3df4xlZX3H8ffHXRRbaYHulWz40VGLtRsbFzPdYmxaBTUUE8HUGEi024R0xdZGU9OU6h/V/kggqZI0MbZroGwbf1HUsvFHW4oYghHsoOuygAri2kJXdqyikqZU8Ns/7sFOxpm9Z+f+2qf7fiU3c85znnvP9+HOfjjz3HPuSVUhSWrPU+ZdgCRpYwxwSWqUAS5JjTLAJalRBrgkNWrzLHe2ZcuWWlhYmOUuJal5d95557eqarC6faYBvrCwwNLS0ix3KUnNS/KNtdqdQpGkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEbN9ErMcSxc8Ym57fvgla+c274laT0egUtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUSMDPMmJST6f5EtJ7k7yzq79uiRfT7Kve2yferWSpB/p822EjwHnVdWjSU4AbkvyqW7bH1TVDdMrT5K0npEBXlUFPNqtntA9appFSZJG6zUHnmRTkn3AYeCmqrqj2/TnSfYnuTrJ09Z57q4kS0mWlpeXJ1O1JKlfgFfVE1W1HTgD2JHk+cAfAc8Dfgk4FfjDdZ67u6oWq2pxMBhMpmpJ0tGdhVJVjwC3ABdU1aEaegz4G2DHFOqTJK2jz1kogyQnd8tPB14OfDnJ1q4twMXAgemVKUlarc9ZKFuBPUk2MQz866vq40k+nWQABNgHXD69MiVJq/U5C2U/cM4a7edNpSJJUi9eiSlJjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVF9bmp8YpLPJ/lSkruTvLNrf1aSO5Lcn+TDSZ46/XIlSU/qcwT+GHBeVb0A2A5ckORc4Crg6qr6OeA7wGVTq1KS9GNGBngNPdqtntA9CjgPuKFr3wNcPI0CJUlr6zUHnmRTkn3AYeAm4GvAI1X1eNflQeD0dZ67K8lSkqXl5eUJlCxJgp4BXlVPVNV24AxgB/C8vjuoqt1VtVhVi4PBYGNVSpJ+zFGdhVJVjwC3AC8CTk6yudt0BvDQZEuTJB1Jn7NQBklO7pafDrwcuJdhkL+m67YTuHFKNUqS1rB5dBe2AnuSbGIY+NdX1ceT3AN8KMmfAV8ErplinZKkVUYGeFXtB85Zo/0BhvPhkqQ58EpMSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmN6nNT4zOT3JLkniR3J3lz1/6OJA8l2dc9Lpx+uZKkJ/W5qfHjwFur6gtJTgLuTHJTt+3qqvqL6ZUnSVpPn5saHwIOdcvfT3IvcPq0C5MkHdlRzYEnWWB4h/o7uqY3Jdmf5Nokp0y6OEnS+noHeJJnAB8B3lJV3wPeCzwH2M7wCP1d6zxvV5KlJEvLy8vjVyxJAnoGeJITGIb3+6vqowBV9XBVPVFVPwTeB+xY67lVtbuqFqtqcTAYTKpuSTru9TkLJcA1wL1V9e4V7VtXdHs1cGDy5UmS1tPnLJQXA68H7kqyr2t7G3Bpku1AAQeBN0yhPknSOvqchXIbkDU2fXLy5UiS+vJKTElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRfe5Kf2aSW5Lck+TuJG/u2k9NclOS+7qfp0y/XEnSk/ocgT8OvLWqtgHnAr+bZBtwBXBzVZ0N3NytS5JmZGSAV9WhqvpCt/x94F7gdOAiYE/XbQ9w8ZRqlCSt4ajmwJMsAOcAdwCnVdWhbtM3gdPWec6uJEtJlpaXl8epVZK0Qu8AT/IM4CPAW6rqeyu3VVUBtdbzqmp3VS1W1eJgMBirWEnS/+kV4ElOYBje76+qj3bNDyfZ2m3fChyeTomSpLX0OQslwDXAvVX17hWb9gI7u+WdwI2TL0+StJ7NPfq8GHg9cFeSfV3b24ArgeuTXAZ8A3jtVCqUJK1pZIBX1W1A1tl8/mTLkST15ZWYktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIa1eemxtcmOZzkwIq2dyR5KMm+7nHhdMuUJK3W5wj8OuCCNdqvrqrt3eOTky1LkjTKyACvqluBb8+gFknSURhnDvxNSfZ3UyynrNcpya4kS0mWlpeXx9idJGmljQb4e4HnANuBQ8C71utYVburarGqFgeDwQZ3J0labUMBXlUPV9UTVfVD4H3AjsmWJUkaZUMBnmTritVXAwfW6ytJmo7Nozok+SDwEmBLkgeBPwZekmQ7UMBB4A3TK1GStJaRAV5Vl67RfM0UapEkHQWvxJSkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1KiRAZ7k2iSHkxxY0XZqkpuS3Nf9PGW6ZUqSVutzBH4dcMGqtiuAm6vqbODmbl2SNEMjA7yqbgW+var5ImBPt7wHuHiyZUmSRtnoHPhpVXWoW/4mcNp6HZPsSrKUZGl5eXmDu5MkrTb2h5hVVUAdYfvuqlqsqsXBYDDu7iRJnY0G+MNJtgJ0Pw9PriRJUh8bDfC9wM5ueSdw42TKkST11ec0wg8CnwN+PsmDSS4DrgRenuQ+4GXduiRphjaP6lBVl66z6fwJ1yJJOgpeiSlJjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEjb6l2JEkOAt8HngAer6rFSRQlSRptrADvvLSqvjWB15EkHQWnUCSpUeMGeAH/nOTOJLsmUZAkqZ9xp1B+paoeSvJM4KYkX66qW1d26IJ9F8BZZ5015u4kSU8a6wi8qh7qfh4GPgbsWKPP7qparKrFwWAwzu4kSStsOMCT/GSSk55cBl4BHJhUYZKkIxtnCuU04GNJnnydD1TVP06kKknSSBsO8Kp6AHjBBGuRJB0FTyOUpEYZ4JLUKANckhplgEtSowxwSWrUJL7MSpKasHDFJ+a274NXvnLir+kRuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqPGCvAkFyT5SpL7k1wxqaIkSaNtOMCTbALeA/w6sA24NMm2SRUmSTqycY7AdwD3V9UDVfU/wIeAiyZTliRplHFu6HA68O8r1h8Efnl1pyS7gF3d6qNJvrLB/W0BvrXB544lV81jr8AcxzxHjvn4cNyNOVeNNeafXatx6nfkqardwO5xXyfJUlUtTqCkZjjm44NjPj5MY8zjTKE8BJy5Yv2Mrk2SNAPjBPi/AmcneVaSpwKXAHsnU5YkaZQNT6FU1eNJ3gT8E7AJuLaq7p5YZT9u7GmYBjnm44NjPj5MfMypqkm/piRpBrwSU5IaZYBLUqOOuQAfdXl+kqcl+XC3/Y4kC3Moc6J6jPn3k9yTZH+Sm5OseU5oS/p+DUOS30hSSZo+5azPeJO8tnuf707ygVnXOGk9fq/PSnJLki92v9sXzqPOSUpybZLDSQ6ssz1J/rL7b7I/yQvH2mFVHTMPhh+Gfg14NvBU4EvAtlV9fgf4q275EuDD8657BmN+KfAT3fIbj4cxd/1OAm4FbgcW5133lN/js4EvAqd068+cd90zGPNu4I3d8jbg4LzrnsC4fxV4IXBgne0XAp8CApwL3DHO/o61I/A+l+dfBOzplm8Azk+SGdY4aSPHXFW3VNV/dau3MzznvmV9v4bhT4GrgP+eZXFT0Ge8vw28p6q+A1BVh2dc46T1GXMBP9Ut/zTwHzOsbyqq6lbg20fochHwtzV0O3Bykq0b3d+xFuBrXZ5/+np9qupx4LvAz8ykuunoM+aVLmP4f/CWjRxz96flmVX1iVkWNiV93uPnAs9N8tkktye5YGbVTUefMb8DeF2SB4FPAr83m9Lm6mj/vR/R1C+l1+QkeR2wCPzavGuZpiRPAd4N/NacS5mlzQynUV7C8C+sW5P8YlU9Ms+ipuxS4LqqeleSFwF/l+T5VfXDeRfWimPtCLzP5fk/6pNkM8M/vf5zJtVNR6+vJEjyMuDtwKuq6rEZ1TYto8Z8EvB84DNJDjKcK9zb8AeZfd7jB4G9VfWDqvo68FWGgd6qPmO+DLgeoKo+B5zI8Euu/j+b6FeQHGsB3ufy/L3Azm75NcCnq/t0oFEjx5zkHOCvGYZ363OjMGLMVfXdqtpSVQtVtcBw3v9VVbU0n3LH1uf3+h8YHn2TZAvDKZUHZljjpPUZ878B5wMk+QWGAb480ypnby/wm93ZKOcC362qQxt+tXl/arvOp7RfZfgJ9tu7tj9h+A8Yhm/y3wP3A58Hnj3vmmcw5n8BHgb2dY+986552mNe1fczNHwWSs/3OAynje4B7gIumXfNMxjzNuCzDM9Q2Qe8Yt41T2DMHwQOAT9g+FfVZcDlwOUr3uf3dP9N7hr399pL6SWpUcfaFIokqScDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXqfwFp9cxOq1tqfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist([int(x) for x in scores.values() if x != 'NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80018a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "383611c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score average: 0.41 samples_count: 1710\n"
     ]
    }
   ],
   "source": [
    "average, count = get_scores_weighted_average(scores, counts)\n",
    "number_of_warnings = len([scores[k] for k in scores if scores[k] != 'NA'])\n",
    "\n",
    "# assert count == counter, 'counts must be equal'\n",
    "\n",
    "scores[\"average\"] = average\n",
    "scores['number_of_warnings'] = number_of_warnings\n",
    "scores['samples_count'] = count\n",
    "\n",
    "print(f'score average: {average:.2f} samples_count: {scores[\"samples_count\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3bcd125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1710, 101430)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99106025",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fff62ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix no-throw-literal Expected an object to be thrown. throw \"Malformed date format: \" + format; : catch (exc) { throw \"Malformed date format: \" + format; }\n"
     ]
    }
   ],
   "source": [
    "print(test_info['no-throw-literal'][ind].predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2d025c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix no-throw-literal Expected an object to be thrown.     throw \"Malformed date format: \" + format;\n",
      ":\n",
      "  catch (exc) {\n",
      "    throw \"Malformed date format: \" + format;\n",
      "  }\n",
      "\n",
      " </s>\n"
     ]
    }
   ],
   "source": [
    "print(test_info['no-throw-literal'][ind].GetT5Representation(True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2944778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  catch (exc) {\n",
      "    throw new Error(\"Malformed date format: \" + format);\n",
      "  }\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_info['no-throw-literal'][ind].target_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df2ccead",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = defaultdict(int)\n",
    "for warning in scores:\n",
    "    for item in test_info[warning]:\n",
    "        repos[item.repo] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfdb6fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/data/all/data/qooxdoo/qooxdoo': 432,\n",
       " '/data/all/data/elastic/kibana': 180,\n",
       " '/data/all/data/emberjs/ember.js': 171,\n",
       " '/data/all/data/zloirock/core-js': 160,\n",
       " '/data/all/data/Encapsule-Annex/onm': 155,\n",
       " '/data/all/data/sequelize/sequelize': 140,\n",
       " '/data/all/data/dcos/dcos-ui': 129,\n",
       " '/data/all/data/LivelyKernel/LivelyKernel': 123,\n",
       " '/data/all/data/svgdotjs/svg.js': 118,\n",
       " '/data/all/data/foam-framework/foam': 102,\n",
       " '/data/all/data/ctx-core/ctx-core': 8,\n",
       " '/data/all/data/duojs/duo': 6,\n",
       " '/data/all/data/GoogleChrome/lighthouse': 4,\n",
       " '/data/all/data/tlrobinson/streampunk.js': 4,\n",
       " '/data/all/data/patrickjquinn/P-Brain.ai': 3,\n",
       " '/data/all/data/coreyp1/defiant': 3,\n",
       " '/data/all/data/applitopia/immutable-sorted': 3,\n",
       " '/data/all/data/SuperMap/iClient-JavaScript': 2,\n",
       " '/data/all/data/open-webrtc-toolkit/owt-client-javascript': 2,\n",
       " '/data/all/data/basicdays/co-pg': 2,\n",
       " '/data/all/data/eggjs/egg-view-nunjucks': 2,\n",
       " '/data/all/data/nypublicradio/ember-hifi': 2,\n",
       " '/data/all/data/andreasasprou/react-boilerplate-auth': 2,\n",
       " '/data/all/data/ptariche/koa-waterline': 2,\n",
       " '/data/all/data/wavesjs/waves-ui': 2,\n",
       " '/data/all/data/infernojs/inferno': 2,\n",
       " '/data/all/data/react-native-community/react-native-google-analytics': 2,\n",
       " '/data/all/data/HospitalRun/hospitalrun-frontend': 2,\n",
       " '/data/all/data/lorenzofox3/zora': 2,\n",
       " '/data/all/data/apache/cordova-js': 1,\n",
       " '/data/all/data/kvz/locutus': 1,\n",
       " '/data/all/data/sstrigler/JSJaC': 1,\n",
       " '/data/all/data/redhat-developer-tooling/developer-platform-install': 1,\n",
       " '/data/all/data/shakilsiraj/json-object-mapper': 1,\n",
       " '/data/all/data/PrismarineJS/mineflayer': 1,\n",
       " '/data/all/data/standard-things/esm': 1,\n",
       " '/data/all/data/jychri/google-apps-script-cheat-sheet': 1,\n",
       " '/data/all/data/Caltech-IPAC/firefly': 1,\n",
       " '/data/all/data/idchlife/node-telegram-bot-api-middleware': 1,\n",
       " '/data/all/data/zce/koa-xtpl': 1,\n",
       " '/data/all/data/dominhhai/koa-log4js': 1,\n",
       " '/data/all/data/marmelab/ZeroDollarHomePage': 1,\n",
       " '/data/all/data/iyobo/jollofjs': 1,\n",
       " '/data/all/data/addthis/fluxthis': 1,\n",
       " '/data/all/data/digitarald/acmejs': 1,\n",
       " '/data/all/data/mohebifar/lithree.js': 1,\n",
       " '/data/all/data/purpurina-engine/scintilla': 1,\n",
       " '/data/all/data/eden-js/cli': 1,\n",
       " '/data/all/data/youseries/ureport': 1,\n",
       " '/data/all/data/postcss/postcss': 1,\n",
       " '/data/all/data/ReactiveX/rxjs': 1,\n",
       " '/data/all/data/iceddev/frozen': 1,\n",
       " '/data/all/data/rgbkrk/atom-script': 1,\n",
       " '/data/all/data/wangzuo/arel': 1,\n",
       " '/data/all/data/wavesjs/waves-lfo': 1,\n",
       " '/data/all/data/uikit/uikit': 1,\n",
       " '/data/all/data/sidorares/node-rfb2': 1,\n",
       " '/data/all/data/xml3d/shade.js': 1,\n",
       " '/data/all/data/CloudI/CloudI': 1,\n",
       " '/data/all/data/stellar-deprecated/stellar-client': 1,\n",
       " '/data/all/data/evaera/RoVer': 1,\n",
       " '/data/all/data/ckknight/gorillascript': 1,\n",
       " '/data/all/data/pissang/claygl': 1,\n",
       " '/data/all/data/bitpay/bitcore': 1,\n",
       " '/data/all/data/graphsense/graphsense-dashboard': 1,\n",
       " '/data/all/data/lianetoolkit/liane-toolkit': 1,\n",
       " '/data/all/data/speakforme/frontend': 1,\n",
       " '/data/all/data/Autodesk/hig': 1,\n",
       " '/data/all/data/WaftTech/WaftEngine': 1,\n",
       " '/data/all/data/HenryQuan/WoWs-Info-Re': 1,\n",
       " '/data/all/data/jthomas/cfbot': 1,\n",
       " '/data/all/data/davidhu2000/youtube_desktop': 1,\n",
       " '/data/all/data/jjmontesl/cubesviewer': 1,\n",
       " '/data/all/data/BenjaminVanRyseghem/numbro': 1,\n",
       " '/data/all/data/sgoran/micro': 1,\n",
       " '/data/all/data/react-component/table': 1,\n",
       " '/data/all/data/ifvictr/ghost-storage-github': 1,\n",
       " '/data/all/data/dollarshaveclub/es-check': 1,\n",
       " '/data/all/data/andrejewski/cla': 1,\n",
       " '/data/all/data/alm-tools/alm': 1,\n",
       " '/data/all/data/mongolass/mongolass': 1,\n",
       " '/data/all/data/odf/ceci-core': 1,\n",
       " '/data/all/data/larkjs/lark': 1,\n",
       " '/data/all/data/mongodb-js/mongodb-topology-manager': 1,\n",
       " '/data/all/data/1amageek/pring-admin.ts': 1,\n",
       " '/data/all/data/aui/font-spider': 1,\n",
       " '/data/all/data/h5p/h5p-cli': 1,\n",
       " '/data/all/data/eemeli/yaml': 1,\n",
       " '/data/all/data/spencermountain/spacetime': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos = dict(sorted(repos.items(), key=lambda item: item[1], reverse=True))\n",
    "repos # this must be applied on the train data not the test idiot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef355be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo = '/data/all/data/qooxdoo/qooxdoo'\n",
    "# repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = []\n",
    "for repo, cnt in sorted(repos.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "#     print(repo)\n",
    "    for warning in scores:\n",
    "        for item in test_info[warning]:\n",
    "            if item.repo == repo:\n",
    "                data_points.append(MinimalDataPoint(item.predictions, item.target_code, item.repo))\n",
    "                \n",
    "    new_dir = f'{storage_directory}/bt_data/{repo}.json'\n",
    "    print(new_dir)\n",
    "    os.makedirs(new_dir[:new_dir.rfind('/')],exist_ok=True)\n",
    "    with open(new_dir, \"w\", errors=\"ignore\") as f:\n",
    "        json.dump([m.__dict__ for m in data_points], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# new_dir = f'{storage_directory}/bt_data/{repo}.json'\n",
    "# os.makedirs(new_dir[:new_dir.rfind('/')],exist_ok=True)\n",
    "# with open(new_dir, \"w+\", errors=\"ignore\") as f:\n",
    "#     json.dump([m.__dict__ for m in data_points], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53fe63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20826e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654d211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36359dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770ad18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2b42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
