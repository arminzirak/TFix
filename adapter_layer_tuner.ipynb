{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850cb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./hf_transformers/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434900b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Tokenizer\n",
    "from module_utils import AdapterT5Block\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from data_reader import GetDataAsPython\n",
    "from prepare_data import create_data\n",
    "from prepare_data import create_dataset\n",
    "from prepare_data import extract_warning_types\n",
    "from utils import boolean_string\n",
    "from utils import get_current_time\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c2acb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start all: 2022-01-25 18:09:33.898103\n"
     ]
    }
   ],
   "source": [
    "start_all = datetime.now()\n",
    "print(f'start all: {start_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc9058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "503b579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/all/data/qooxdoo/qooxdoo 1\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-r\", \"--repo\", type=str, default='/data/all/data/qooxdoo/qooxdoo')\n",
    "parser.add_argument(\"-p\", \"--percent\", type=float, default=1)\n",
    "parser.add_argument(\"-f\", type=str, required=False)\n",
    "\n",
    "args = parser.parse_args()\n",
    "repo = args.repo\n",
    "sample_percent = args.percent\n",
    "print(repo, sample_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82e3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 't5-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fade2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    storage_directory = './storage/'\n",
    "    base_model = f'./{storage_directory}/training/checkpoint-37375'\n",
    "    adapted_model_dir = './test'\n",
    "    batch_size=16    \n",
    "else:\n",
    "    storage_directory = '/scratch/arminz/'\n",
    "    base_model = f'./{storage_directory}/training/t5-small_repo-based_21-01-2022_10-29-42/checkpoint-16440'\n",
    "    adapted_model_dir = './test'\n",
    "    batch_size=128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf90d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32104, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32104, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32104, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32104, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(base_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(base_model)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeda3ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapter size: 50\n"
     ]
    }
   ],
   "source": [
    "model.config.adapter_size = 50\n",
    "print('adapter size:', model.config.adapter_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98871977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "encoder_config = copy.deepcopy(model.config)\n",
    "encoder_config.is_decoder = False\n",
    "encoder_config.use_cache = False\n",
    "encoder_config.is_encoder_decoder = False\n",
    "encoder_blocks = nn.ModuleList(\n",
    "            [AdapterT5Block(encoder_config, has_relative_attention_bias=bool(i == 0)) for i in range(model.config.num_layers)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "337b302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_config = copy.deepcopy(model.config)\n",
    "decoder_config.is_decoder = True\n",
    "decoder_config.is_encoder_decoder = False\n",
    "decoder_config.num_layers = model.config.num_decoder_layers\n",
    "decoder_blocks = nn.ModuleList(\n",
    "            [AdapterT5Block(decoder_config, has_relative_attention_bias=bool(i == 0)) for i in range(model.config.num_layers)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b0a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(encoder_blocks)):\n",
    "    encoder_blocks[i].load_state_dict(model.encoder.block[i].state_dict(), strict=False)\n",
    "    model.encoder.block[i] = encoder_blocks[i].to('cuda')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9baf064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(decoder_blocks)):\n",
    "    decoder_blocks[i].load_state_dict(model.decoder.block[i].state_dict(), strict=False)\n",
    "    model.decoder.block[i] = decoder_blocks[i].to('cuda')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa1e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = tokenizer(['hi how are you', 'thanks Im fine'], padding=True, return_tensors='pt').to('cuda')\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca6acd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104804"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = GetDataAsPython(f\"{storage_directory}/data_and_models/data/data_autofix_tracking_repo_specific_final.json\")\n",
    "data_eslint = GetDataAsPython(f\"{storage_directory}/data_and_models/data/data_autofix_tracking_eslint_final.json\")\n",
    "data += data_eslint\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84451765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting by : repo-based-included\n",
      "train size: 322\n",
      "val size: 110\n",
      "test size: 115\n"
     ]
    }
   ],
   "source": [
    "all_warning_types = extract_warning_types(data)\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "(repo_train_inputs, repo_train_labels, repo_val_inputs, repo_val_labels, repo_test_inputs, repo_test_labels,\n",
    " repo_train_info, repo_val_info, repo_test_info,) = create_data(data, all_warning_types, include_warning=True,\n",
    "                                                                design='repo-based-included', select_repo=repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d03eb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name='adapterTuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f030e2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec_number: 357\n",
      "saved model directory: ./storage//tmp/adapterTuned_357_qooxdoo_1.0_322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armin/TFix/env/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:185: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "exec_number = random.randint(0, 1000)\n",
    "print('exec_number:', exec_number)\n",
    "tokenizer = T5Tokenizer.from_pretrained(base_model)\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "train_dataset = create_dataset(repo_train_inputs, repo_train_labels, tokenizer, pad_truncate=True, max_length=128)\n",
    "val_dataset = create_dataset(repo_val_inputs, repo_val_labels, tokenizer, pad_truncate=True)\n",
    "# test_dataset = create_dataset(repo_val_inputs, repo_val_labels, tokenizer, pad_truncate=True)\n",
    "# \n",
    "# In[49]:\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "test_result_directory = f'{storage_directory}/{name}'\n",
    "full_name = f'{name}_{exec_number}_{repo.rsplit(\"/\", 1)[1][-20:]}_{1.0}_{len(repo_train_inputs)}'\n",
    "model_directory = f'{storage_directory}/tmp/{full_name}'\n",
    "print('saved model directory:', model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f29e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 4e-3\n",
    "ws = 300\n",
    "wd = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11b3b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for block in model.encoder.block:\n",
    "    for param in block.adapter.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "for block in model.decoder.block:\n",
    "    for param in block.adapter.parameters():\n",
    "        param.requires_grad = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "272b5339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of learnable parameters: 0.01\n"
     ]
    }
   ],
   "source": [
    "freezed, non_freezed = 0, 0\n",
    "for item in model.parameters():\n",
    "    if item.requires_grad:\n",
    "        non_freezed += item.numel()\n",
    "    else:\n",
    "        freezed += item.numel()\n",
    "print(f'percentage of learnable parameters: {non_freezed / (freezed + non_freezed):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb38786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import T5Config\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Tokenizer\n",
    "from transformers import set_seed\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=model_directory,\n",
    "    num_train_epochs=70,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=ws,\n",
    "    weight_decay=wd,\n",
    "    logging_dir=model_directory,\n",
    "    logging_steps=100,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=lr,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=1,\n",
    "    eval_accumulation_steps=1,  # set this lower, if testing or validation crashes\n",
    "    disable_tqdm=False,\n",
    "    predict_with_generate=True,  # never set this to false.\n",
    "    seed=42,  # default value\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f16c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    optimizers=[torch.optim.Adam(params=model.parameters(), lr=lr), None],\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)]\n",
    "    #     compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e32d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start tuning: 2022-01-25 18:09:33.898103\n"
     ]
    }
   ],
   "source": [
    "start_tuning = datetime.now()\n",
    "print(f'start tuning: {start_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a2c8bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='378' max='1470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 378/1470 00:50 < 02:26, 7.47 it/s, Epoch 18/70]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.186725</td>\n",
       "      <td>0.289700</td>\n",
       "      <td>379.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.184968</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>377.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.180592</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>377.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.173099</td>\n",
       "      <td>0.294700</td>\n",
       "      <td>373.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.166305</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>377.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.162521</td>\n",
       "      <td>0.290700</td>\n",
       "      <td>378.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>376.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.151126</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>373.367000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.146610</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>377.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.141542</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>391.897000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.272100</td>\n",
       "      <td>404.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.135244</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>390.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.133338</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>387.318000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.131970</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>383.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>380.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.132671</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>333.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.134193</td>\n",
       "      <td>0.278300</td>\n",
       "      <td>395.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.132257</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>379.452000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./storage//tmp/adapterTuned_357_qooxdoo_1.0_322/checkpoint-294 were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.adapter.norm.weight', 'encoder.block.0.adapter.norm.bias', 'encoder.block.0.adapter.down_projection.weight', 'encoder.block.0.adapter.down_projection.bias', 'encoder.block.0.adapter.up_projection.weight', 'encoder.block.0.adapter.up_projection.bias', 'encoder.block.1.adapter.norm.weight', 'encoder.block.1.adapter.norm.bias', 'encoder.block.1.adapter.down_projection.weight', 'encoder.block.1.adapter.down_projection.bias', 'encoder.block.1.adapter.up_projection.weight', 'encoder.block.1.adapter.up_projection.bias', 'encoder.block.2.adapter.norm.weight', 'encoder.block.2.adapter.norm.bias', 'encoder.block.2.adapter.down_projection.weight', 'encoder.block.2.adapter.down_projection.bias', 'encoder.block.2.adapter.up_projection.weight', 'encoder.block.2.adapter.up_projection.bias', 'encoder.block.3.adapter.norm.weight', 'encoder.block.3.adapter.norm.bias', 'encoder.block.3.adapter.down_projection.weight', 'encoder.block.3.adapter.down_projection.bias', 'encoder.block.3.adapter.up_projection.weight', 'encoder.block.3.adapter.up_projection.bias', 'encoder.block.4.adapter.norm.weight', 'encoder.block.4.adapter.norm.bias', 'encoder.block.4.adapter.down_projection.weight', 'encoder.block.4.adapter.down_projection.bias', 'encoder.block.4.adapter.up_projection.weight', 'encoder.block.4.adapter.up_projection.bias', 'encoder.block.5.adapter.norm.weight', 'encoder.block.5.adapter.norm.bias', 'encoder.block.5.adapter.down_projection.weight', 'encoder.block.5.adapter.down_projection.bias', 'encoder.block.5.adapter.up_projection.weight', 'encoder.block.5.adapter.up_projection.bias', 'decoder.block.0.adapter.norm.weight', 'decoder.block.0.adapter.norm.bias', 'decoder.block.0.adapter.down_projection.weight', 'decoder.block.0.adapter.down_projection.bias', 'decoder.block.0.adapter.up_projection.weight', 'decoder.block.0.adapter.up_projection.bias', 'decoder.block.1.adapter.norm.weight', 'decoder.block.1.adapter.norm.bias', 'decoder.block.1.adapter.down_projection.weight', 'decoder.block.1.adapter.down_projection.bias', 'decoder.block.1.adapter.up_projection.weight', 'decoder.block.1.adapter.up_projection.bias', 'decoder.block.2.adapter.norm.weight', 'decoder.block.2.adapter.norm.bias', 'decoder.block.2.adapter.down_projection.weight', 'decoder.block.2.adapter.down_projection.bias', 'decoder.block.2.adapter.up_projection.weight', 'decoder.block.2.adapter.up_projection.bias', 'decoder.block.3.adapter.norm.weight', 'decoder.block.3.adapter.norm.bias', 'decoder.block.3.adapter.down_projection.weight', 'decoder.block.3.adapter.down_projection.bias', 'decoder.block.3.adapter.up_projection.weight', 'decoder.block.3.adapter.up_projection.bias', 'decoder.block.4.adapter.norm.weight', 'decoder.block.4.adapter.norm.bias', 'decoder.block.4.adapter.down_projection.weight', 'decoder.block.4.adapter.down_projection.bias', 'decoder.block.4.adapter.up_projection.weight', 'decoder.block.4.adapter.up_projection.bias', 'decoder.block.5.adapter.norm.weight', 'decoder.block.5.adapter.norm.bias', 'decoder.block.5.adapter.down_projection.weight', 'decoder.block.5.adapter.down_projection.bias', 'decoder.block.5.adapter.up_projection.weight', 'decoder.block.5.adapter.up_projection.bias']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=378, training_loss=0.10771674958486406, metrics={'train_runtime': 50.4792, 'train_samples_per_second': 29.121, 'total_flos': 272099745275904, 'epoch': 18.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2df196b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end tuining: 2022-01-25 18:09:33.898103\n"
     ]
    }
   ],
   "source": [
    "end_tuning = datetime.now()\n",
    "print(f'end tuining: {start_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c78d1246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.18728125095367432\n"
     ]
    }
   ],
   "source": [
    "print('eval', trainer.evaluate()['eval_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ec26b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./test/tokenizer_config.json',\n",
       " './test/special_tokens_map.json',\n",
       " './test/spiece.model',\n",
       " './test/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(adapted_model_dir)\n",
    "tokenizer.save_pretrained(adapted_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "307a4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, block in enumerate(model.encoder.block):\n",
    "    torch.save(block.adapter.state_dict(), f'{adapted_model_dir}/adapter-encoder-{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ba342e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, block in enumerate(model.decoder.block):\n",
    "    torch.save(block.adapter.state_dict(), f'{adapted_model_dir}/adapter-decoder-{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3eafeb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end all: 2022-01-25 18:09:33.898103\n"
     ]
    }
   ],
   "source": [
    "end_all = datetime.now()\n",
    "print(f'end all: {start_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a0837e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('tuner_runtime.csv', 'a') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([name, repo, len(train_dataset), len(val_dataset), base_model, start_all, start_tuning, end_tuning, end_all])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d69a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3df2009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./test were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.adapter.norm.weight', 'encoder.block.0.adapter.norm.bias', 'encoder.block.0.adapter.down_projection.weight', 'encoder.block.0.adapter.down_projection.bias', 'encoder.block.0.adapter.up_projection.weight', 'encoder.block.0.adapter.up_projection.bias', 'encoder.block.1.adapter.norm.weight', 'encoder.block.1.adapter.norm.bias', 'encoder.block.1.adapter.down_projection.weight', 'encoder.block.1.adapter.down_projection.bias', 'encoder.block.1.adapter.up_projection.weight', 'encoder.block.1.adapter.up_projection.bias', 'encoder.block.2.adapter.norm.weight', 'encoder.block.2.adapter.norm.bias', 'encoder.block.2.adapter.down_projection.weight', 'encoder.block.2.adapter.down_projection.bias', 'encoder.block.2.adapter.up_projection.weight', 'encoder.block.2.adapter.up_projection.bias', 'encoder.block.3.adapter.norm.weight', 'encoder.block.3.adapter.norm.bias', 'encoder.block.3.adapter.down_projection.weight', 'encoder.block.3.adapter.down_projection.bias', 'encoder.block.3.adapter.up_projection.weight', 'encoder.block.3.adapter.up_projection.bias', 'encoder.block.4.adapter.norm.weight', 'encoder.block.4.adapter.norm.bias', 'encoder.block.4.adapter.down_projection.weight', 'encoder.block.4.adapter.down_projection.bias', 'encoder.block.4.adapter.up_projection.weight', 'encoder.block.4.adapter.up_projection.bias', 'encoder.block.5.adapter.norm.weight', 'encoder.block.5.adapter.norm.bias', 'encoder.block.5.adapter.down_projection.weight', 'encoder.block.5.adapter.down_projection.bias', 'encoder.block.5.adapter.up_projection.weight', 'encoder.block.5.adapter.up_projection.bias', 'decoder.block.0.adapter.norm.weight', 'decoder.block.0.adapter.norm.bias', 'decoder.block.0.adapter.down_projection.weight', 'decoder.block.0.adapter.down_projection.bias', 'decoder.block.0.adapter.up_projection.weight', 'decoder.block.0.adapter.up_projection.bias', 'decoder.block.1.adapter.norm.weight', 'decoder.block.1.adapter.norm.bias', 'decoder.block.1.adapter.down_projection.weight', 'decoder.block.1.adapter.down_projection.bias', 'decoder.block.1.adapter.up_projection.weight', 'decoder.block.1.adapter.up_projection.bias', 'decoder.block.2.adapter.norm.weight', 'decoder.block.2.adapter.norm.bias', 'decoder.block.2.adapter.down_projection.weight', 'decoder.block.2.adapter.down_projection.bias', 'decoder.block.2.adapter.up_projection.weight', 'decoder.block.2.adapter.up_projection.bias', 'decoder.block.3.adapter.norm.weight', 'decoder.block.3.adapter.norm.bias', 'decoder.block.3.adapter.down_projection.weight', 'decoder.block.3.adapter.down_projection.bias', 'decoder.block.3.adapter.up_projection.weight', 'decoder.block.3.adapter.up_projection.bias', 'decoder.block.4.adapter.norm.weight', 'decoder.block.4.adapter.norm.bias', 'decoder.block.4.adapter.down_projection.weight', 'decoder.block.4.adapter.down_projection.bias', 'decoder.block.4.adapter.up_projection.weight', 'decoder.block.4.adapter.up_projection.bias', 'decoder.block.5.adapter.norm.weight', 'decoder.block.5.adapter.norm.bias', 'decoder.block.5.adapter.down_projection.weight', 'decoder.block.5.adapter.down_projection.bias', 'decoder.block.5.adapter.up_projection.weight', 'decoder.block.5.adapter.up_projection.bias']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/armin/TFix/env/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:185: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "21it [00:22,  1.10s/it]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:  18:11:02\n",
      "['no-invalid-this', 'no-throw-literal', 'no-new-wrappers', 'guard-for-in', 'no-new-object', 'comma-style', 'prefer-spread', 'no-caller', 'no-extra-bind', 'no-array-constructor', 'prefer-rest-params', 'generator-star-spacing', 'no-this-before-super', 'no-extend-native', 'no-undef', 'no-useless-escape', 'no-dupe-keys', 'no-console', 'no-constant-condition', 'no-duplicate-case', 'no-empty', 'no-extra-semi', 'no-redeclare', 'no-cond-assign', 'no-extra-boolean-cast', 'no-fallthrough', 'no-unreachable', 'valid-typeof', 'no-unsafe-finally', 'no-unused-vars', 'no-debugger', 'no-unsafe-negation', 'no-case-declarations', 'no-self-assign', 'no-process-exit', 'no-inner-declarations', 'for-direction', 'no-compare-neg-zero', 'no-sparse-arrays', 'no-func-assign', 'no-const-assign', 'no-global-assign', 'use-isnan', 'no-unused-labels', 'require-yield', 'getter-return', 'no-dupe-class-members', 'no-ex-assign', 'constructor-super', 'no-new-symbol', 'no-empty-pattern', 'no-class-assign']\n",
      "splitting by : repo-based-included\n",
      "train size: 322\n",
      "val size: 110\n",
      "test size: 115\n",
      "Loaded tokenizer from directory ./test\n",
      "Loaded model from directory ./test\n",
      "cuda:0\n",
      "Testing has started\n",
      "Number of testing samples:  115\n",
      "score average: 0.5826086956521739 samples_count: 115\n",
      "result : ./storage//25/per-repo/t5-small_test_qooxdoo_25-01-2022_18-11-02\n",
      "end time:  18:11:35\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = os.system(f'python hf_transformers/tfix_testing_adapterLayer.py --load-model {adapted_model_dir} -bs {batch_size} --model-name {model_name} -d repo-based-included -r {repo}')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "908788dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(adapted_model_dir)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242e40a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}