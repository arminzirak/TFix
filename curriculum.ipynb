{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2cd3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3653674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import T5Config\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Tokenizer\n",
    "from transformers import set_seed\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"./hf_transformers/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b62dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data_reader import GetDataAsPython\n",
    "from prepare_data import create_data\n",
    "from prepare_data import create_dataset\n",
    "from prepare_data import extract_warning_types\n",
    "from utils import boolean_string\n",
    "from utils import get_current_time\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from data_reader import GetDataAsPython\n",
    "from prepare_data import create_data\n",
    "from prepare_data import create_dataset\n",
    "from prepare_data import extract_warning_types\n",
    "from utils import boolean_string\n",
    "from utils import get_current_time\n",
    "import csv\n",
    "\n",
    "start_all = datetime.now()\n",
    "\n",
    "# In[6]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc64c9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local = True\n",
    "base_model = 'training/t5-small_repo-based_21-01-2022_10-29-42/checkpoint-16440'\n",
    "\n",
    "if local:\n",
    "    storage_directory = './storage/'\n",
    "    load_model = f'./{storage_directory}/{base_model}'\n",
    "    batch_size = 16\n",
    "else:\n",
    "    storage_directory = '/scratch/arminz/'\n",
    "    batch_size = 64\n",
    "    load_model = f'/{storage_directory}/{base_model}'\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "exec_number = random.randint(0, 1000)\n",
    "exec_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed201ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: /data/all/data/qooxdoo/qooxdoo 1\n",
      "best arguments 0.004 0.4 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104804"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"-r\", \"--repo\", type=str, default='/data/all/data/oroinc/platform')\n",
    "# parser.add_argument(\"-p\", \"--percent\", type=float, default=1)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "repo = \"/data/all/data/qooxdoo/qooxdoo\" #args.repo\n",
    "sample_percent = 1#args.percent\n",
    "\n",
    "print('start:', repo, sample_percent)\n",
    "\n",
    "lr = 4e-3\n",
    "ws = 300\n",
    "wd = 0.4\n",
    "print('best arguments', lr, wd, ws)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "name='curr'\n",
    "name\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "# Read and prepare data\n",
    "data = GetDataAsPython(f\"{storage_directory}/data_and_models/data/data_autofix_tracking_repo_specific_final.json\")\n",
    "data_eslint = GetDataAsPython(f\"{storage_directory}/data_and_models/data/data_autofix_tracking_eslint_final.json\")\n",
    "data += data_eslint\n",
    "\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160698b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting by : repo-based-included\n",
      "train size: 322\n",
      "val size: 110\n",
      "test size: 115\n",
      "amount of data that is being used for fine-tuning (train) : 322 == 322 (1)\n",
      "amount of data that is being used for fine-tuning (validation): 110 (full)\n",
      "amount of data that will be probably being used for testing: 115 (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armin/TFix/env/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:185: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_warning_types = extract_warning_types(data)\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "(train_inputs, train_labels, val_inputs, val_labels, test_inputs, test_labels, train_info, val_info, test_info, ) = \\\n",
    "    create_data(data, all_warning_types, include_warning=True, design='repo-based-included', select_repo=repo)\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(load_model)\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "len(train_inputs)\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "\n",
    "# Create dataset required by pytorch\n",
    "samples = int(sample_percent * len(train_inputs))\n",
    "train_dataset = create_dataset(train_inputs[:samples], train_labels[:samples], tokenizer, pad_truncate=True, max_length=128)\n",
    "val_dataset = create_dataset(val_inputs, val_labels, tokenizer, pad_truncate=True)\n",
    "\n",
    "print(f'amount of data that is being used for fine-tuning (train) : {len(train_dataset)} == {samples} ({sample_percent})')\n",
    "print(f'amount of data that is being used for fine-tuning (validation): {len(val_dataset)} (full)')\n",
    "print(f'amount of data that will be probably being used for testing: {sum([len(x) for x in test_inputs.values()])} (full)')\n",
    "\n",
    "# In[61]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac60d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_data.BugFixDataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d183f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91695e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "# checkpoint = \"bert-base-uncased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "# def tokenize_function(example):\n",
    "#     return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "# tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e07ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler, SequentialSampler\n",
    "from typing import Sized, Iterator\n",
    "class MySampler(Sampler[int]):\n",
    "    data_source: Sized\n",
    "    \n",
    "    def __init__(self, data_source: Sized) -> None:\n",
    "        self.data_source = data_source\n",
    "        self.priority =  np.zeros(len(data_source))\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        return reversed(np.argsort(self.priority))\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_source)\n",
    "\n",
    "    def set_priority(self, priority):\n",
    "        self.priority = priority\n",
    "        \n",
    "sampler = MySampler(train_dataset)\n",
    "# list(MySampler([1, 2, 3, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505a8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)#, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(val_dataset, batch_size)#, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed44ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader.sampler.set_priority(list(range(len(train_dataset) - 1)) + [-5])\n",
    "# for ind, batch in train_dataloader:\n",
    "#     print(ind)\n",
    "# {k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53655343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15579a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./storage//tmp/finetuned/curr_640_qooxdoo_1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "now = datetime.now()\n",
    "full_name = f'{name}_{exec_number}_{repo.rsplit(\"/\", 1)[1][-20:]}_{sample_percent}'\n",
    "model_directory = f'{storage_directory}/tmp/finetuned/{full_name}'\n",
    "model_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e6e693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32104, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32104, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32104, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32104, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(load_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(load_model)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8795d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed68d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.array(outputs[1].argmax(-1).to('cpu'))\n",
    "# labels = np.array(batch['labels'].to('cpu'))\n",
    "# np.sum(np.all(np.equal(predictions, labels), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6257170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fca80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "838f4fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_training_steps = num_train_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=ws,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7461a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d9bff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, batch in train_dataloader:\n",
    "#     batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "#     print(index)#, batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "321a7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [value.item() for key, value in sorted(list(zip(list(sampler)[:16], outputs[1].max(-1).values.sum(1))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a88290fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "scores = []\n",
    "for batch in train_dataloader:\n",
    "    batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    scores += [item.item() for item in outputs[1].max(-1).values.mean(1).to('cpu')]\n",
    "    \n",
    "# # print(f'epoch #{epoch} | loss: {loss:.2f}, accuracy : {all_corrects/ all_cnt:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6871a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "# [item.item() for item in softmax(outputs[1], dim=-1).max(-1).values.prod(-1).to('cpu')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "999b42ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50, 75], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (outputs[1].argmax(-1) != 0).sum(-1) # length\n",
    "(batch['input_ids'] != 0).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4011480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e294fa7c3ff64eaca6e1221e3bb678f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=630.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #0 | tr_loss:0.14 tr_acc:0.4720496894409938 val_loss: 0.34, val_accuracy: 0.409\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #1 | tr_loss:0.09 tr_acc:0.46273291925465837 val_loss: 0.33, val_accuracy: 0.400\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #2 | tr_loss:0.05 tr_acc:0.4937888198757764 val_loss: 0.36, val_accuracy: 0.236\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #3 | tr_loss:0.05 tr_acc:0.4813664596273292 val_loss: 0.37, val_accuracy: 0.264\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #4 | tr_loss:0.07 tr_acc:0.4409937888198758 val_loss: 0.50, val_accuracy: 0.291\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #5 | tr_loss:0.11 tr_acc:0.39751552795031053 val_loss: 0.51, val_accuracy: 0.227\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #6 | tr_loss:0.04 tr_acc:0.4192546583850932 val_loss: 0.59, val_accuracy: 0.236\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #7 | tr_loss:0.04 tr_acc:0.4254658385093168 val_loss: 0.58, val_accuracy: 0.245\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #8 | tr_loss:0.03 tr_acc:0.4254658385093168 val_loss: 0.59, val_accuracy: 0.218\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #9 | tr_loss:0.04 tr_acc:0.40372670807453415 val_loss: 0.63, val_accuracy: 0.191\n",
      "[181, 78, 284, 291, 2, 107, 298, 127, 71, 16, 105, 148, 304, 109, 94, 283, 29, 98, 80, 35, 48, 87, 101, 315, 68, 10, 1, 51, 106, 96, 121, 3, 72, 286, 15, 24, 317, 12, 58, 30, 55, 79, 61, 92, 75, 299, 60, 294, 111, 167, 287, 108, 117, 100, 157, 297, 93, 32, 208, 303, 8, 293, 90, 184, 104, 128, 9, 37, 215, 13, 73, 221, 86, 34, 57, 41, 91, 103, 125, 7, 236, 33, 132, 47, 279, 314, 110, 288, 274, 22, 122, 163, 223, 319, 0, 63, 54, 321, 318, 112, 56, 26, 309, 312, 306, 124, 250, 216, 83, 203, 281, 85, 65, 62, 50, 259, 40, 256, 27, 123, 131, 198, 141, 261, 153, 113, 66, 89, 76, 290, 46, 264, 219, 305, 249, 257, 43, 292, 289, 28, 133, 64, 143, 52, 151, 42, 23, 316, 70, 285, 205, 31, 11, 245, 25, 191, 280, 20, 59, 6, 4, 275, 5, 88, 232, 84, 74, 258, 21, 136, 129, 196, 49, 44, 182, 19, 18, 255, 307, 194, 38, 115, 142, 267, 45, 144, 77, 246, 302, 183, 14, 162, 172, 260, 134, 193, 254, 276, 240, 296, 218, 95, 114, 189, 178, 17, 238, 273, 160, 69, 268, 137, 174, 207, 211, 82, 155, 253, 99, 36, 230, 186, 119, 180, 270, 120, 199, 176, 171, 170, 241, 165, 53, 138, 247, 204, 226, 213, 118, 251, 190, 139, 266, 67, 242, 217, 225, 81, 192, 301, 272, 188, 116, 168, 269, 220, 39, 135, 235, 209, 239, 228, 237, 195, 147, 206, 166, 150, 313, 214, 97, 177, 201, 265, 185, 145, 248, 310, 212, 278, 271, 311, 152, 234, 222, 231, 233, 277, 140, 202, 156, 197, 187, 263, 224, 252, 175, 149, 227, 295, 308, 282, 179, 244, 169, 126, 102, 158, 159, 164, 173, 300, 146, 154, 229, 210, 243, 200, 161, 262, 320, 130]\n",
      "---\n",
      "epoch #10 | tr_loss:0.02 tr_acc:0.37888198757763975 val_loss: 0.62, val_accuracy: 0.209\n",
      "terminating... using 0\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_train_epochs * len(train_dataloader)))\n",
    "\n",
    "model.train()\n",
    "best_val_accuracy, best_val_loss = 0, 1\n",
    "patience = 10\n",
    "best_model = copy.deepcopy(model)\n",
    "no_imp = 0\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    if epoch == 0  or True:\n",
    "        model.eval()\n",
    "        scores = []\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "    #         scores += [item.item() for item in outputs[1].max(-1).values.mean(1).to('cpu')]\n",
    "#             scores += [item.item() for item in softmax(outputs[1], dim=-1).max(-1).values.prod(-1).to('cpu')]\n",
    "#             scores += list((outputs[1].argmax(-1).to('cpu') != 0).sum(-1)) # length of labels\n",
    "            scores += list((batch['input_ids'] != 0).sum(1).cpu())\n",
    "        new_priorities = [value for key, value in sorted(list(zip(list(sampler), scores)))]    \n",
    "        sampler.set_priority(new_priorities)\n",
    "        print(list(sampler))\n",
    "        print('---')\n",
    "    \n",
    "    model.train()\n",
    "    all_corrects, all_cnt = 0, 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs[0]#outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        predictions = np.array(outputs[1].argmax(-1).to('cpu'))\n",
    "        labels = np.array(batch['labels'].to('cpu'))\n",
    "        corrects = np.sum(np.all(np.equal(predictions, labels), axis=1))\n",
    "        \n",
    "        all_cnt += len(batch['labels'])\n",
    "        all_corrects += corrects\n",
    "        \n",
    "#     print(f'epoch #{epoch} | loss: {loss:.2f}, accuracy : {all_corrects/ all_cnt:.3f}')    \n",
    "    \n",
    "    val_corrects, val_cnt = 0, 0\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        val_loss = outputs[0]\n",
    "        predictions = np.array(outputs[1].argmax(-1).to('cpu'))\n",
    "        labels = np.array(batch['labels'].to('cpu'))\n",
    "        corrects = np.sum(np.all(np.equal(predictions, labels), axis=1))\n",
    "        val_cnt += len(batch['labels'])\n",
    "        val_corrects += corrects\n",
    "    val_accuracy = val_corrects/ val_cnt\n",
    "    print(f'epoch #{epoch} | tr_loss:{loss:.2f} tr_acc:{all_corrects/all_cnt} val_loss: {val_loss:.2f}, val_accuracy: {val_accuracy:.3f}')    \n",
    "    \n",
    "    \n",
    "    if  val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        no_imp = 0\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_epoch = epoch\n",
    "    else:\n",
    "        no_imp += 1\n",
    "    if no_imp >= patience:\n",
    "        print(f'terminating... using {best_epoch}')\n",
    "        break\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f1a4a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #10 | loss: 0.30, accuracy : 0.518\n"
     ]
    }
   ],
   "source": [
    "all_corrects, all_cnt = 0, 0\n",
    "best_model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = best_model(**batch)\n",
    "    loss = outputs[0]\n",
    "    predictions = np.array(outputs[1].argmax(-1).to('cpu'))\n",
    "    labels = np.array(batch['labels'].to('cpu'))\n",
    "    corrects = np.sum(np.all(np.equal(predictions, labels), axis=1))\n",
    "\n",
    "    all_cnt += len(batch['labels'])\n",
    "    all_corrects += corrects\n",
    "    \n",
    "print(f'epoch #{epoch} | loss: {loss:.2f}, accuracy : {all_corrects/ all_cnt:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb4b9639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "506c12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# import numpy as np\n",
    "# def compute_metrics(p):\n",
    "#     target_max_length = 256\n",
    "#     predictions, labels = p.predictions, p.label_ids\n",
    "    \n",
    "#     predictions = np.pad(predictions, ((0, 0), (0, target_max_length - predictions.shape[1])), mode=\"constant\")\n",
    "#     predictions = np.delete(predictions, 0, axis=1)\n",
    "#     predictions = np.insert(predictions, target_max_length - 1, 0, axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "#     labels = np.array(labels)\n",
    "#     labels = np.pad(labels, ((0, 0), (0, target_max_length - labels.shape[1])), mode=\"constant\")\n",
    "#     labels = np.delete(labels, 0, axis=1)\n",
    "#     labels = np.insert(labels, target_max_length - 1, 0, axis=1)\n",
    "    \n",
    "\n",
    "#     correct_counter = np.sum(np.all(np.equal(labels, predictions), axis=1))\n",
    "#     return {'acc': int(correct_counter)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bb601ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=model_directory,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=ws,\n",
    "    weight_decay=wd,\n",
    "    logging_dir=model_directory,\n",
    "    logging_steps=100,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=lr,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=1,\n",
    "    eval_accumulation_steps=1,  # set this lower, if testing or validation crashes\n",
    "    disable_tqdm=False,\n",
    "    predict_with_generate=True,  # never set this to false.\n",
    "    seed=42,  # default value\n",
    ")\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=best_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    optimizers=[torch.optim.Adam(params=model.parameters(), lr=lr), None],\n",
    "    tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1efc8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# import numpy as np\n",
    "# def compute_metrics(p):\n",
    "#     target_max_length = 256\n",
    "#     predictions, labels = p.predictions, p.label_ids\n",
    "    \n",
    "#     predictions = np.pad(predictions, ((0, 0), (0, target_max_length - predictions.shape[1])), mode=\"constant\")\n",
    "#     predictions = np.delete(predictions, 0, axis=1)\n",
    "#     predictions = np.insert(predictions, target_max_length - 1, 0, axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "#     labels = np.array(labels)\n",
    "#     labels = np.pad(labels, ((0, 0), (0, target_max_length - labels.shape[1])), mode=\"constant\")\n",
    "#     labels = np.delete(labels, 0, axis=1)\n",
    "#     labels = np.insert(labels, target_max_length - 1, 0, axis=1)\n",
    "    \n",
    "\n",
    "#     correct_counter = np.sum(np.all(np.equal(labels, predictions), axis=1))\n",
    "#     return {'acc': int(correct_counter)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dafc1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ee3518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import EarlyStoppingCallback\n",
    "\n",
    "# trainer = Seq2SeqTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     optimizers=[torch.optim.Adam(params=model.parameters(), lr=lr), None],\n",
    "#     tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     callbacks=[EarlyStoppingCallback(early_stopping_patience=4)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3512e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start_training = datetime.now()\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "# end_training = datetime.now()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ff65a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tuned_model_dir = f'{model_directory}/best'\n",
    "# tuned_model_dir='/scratch/arminz/tmp/finetuned'\n",
    "trainer.save_model(tuned_model_dir)\n",
    "\n",
    "\n",
    "end_all = datetime.now()\n",
    "# import csv\n",
    "# with open('tuner_runtime.csv', 'a') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     writer.writerow([name, repo, len(train_dataset), len(val_dataset), base_model, start_all, start_training, end_training, end_all])\n",
    "\n",
    "# In[78]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "999967a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local:\n",
    "    from numba import cuda\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cd44b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armin/TFix/env/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:185: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "21it [00:17,  1.43it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:  00:17:06\n",
      "['no-invalid-this', 'no-throw-literal', 'no-new-wrappers', 'guard-for-in', 'no-new-object', 'comma-style', 'prefer-spread', 'no-caller', 'no-extra-bind', 'no-array-constructor', 'prefer-rest-params', 'generator-star-spacing', 'no-this-before-super', 'no-extend-native', 'no-undef', 'no-useless-escape', 'no-dupe-keys', 'no-console', 'no-constant-condition', 'no-duplicate-case', 'no-empty', 'no-extra-semi', 'no-redeclare', 'no-cond-assign', 'no-extra-boolean-cast', 'no-fallthrough', 'no-unreachable', 'valid-typeof', 'no-unsafe-finally', 'no-unused-vars', 'no-debugger', 'no-unsafe-negation', 'no-case-declarations', 'no-self-assign', 'no-process-exit', 'no-inner-declarations', 'for-direction', 'no-compare-neg-zero', 'no-sparse-arrays', 'no-func-assign', 'no-const-assign', 'no-global-assign', 'use-isnan', 'no-unused-labels', 'require-yield', 'getter-return', 'no-dupe-class-members', 'no-ex-assign', 'constructor-super', 'no-new-symbol', 'no-empty-pattern', 'no-class-assign']\n",
      "splitting by : repo-based-included\n",
      "train size: 322\n",
      "val size: 110\n",
      "test size: 115\n",
      "Loaded tokenizer from directory ./storage//tmp/finetuned/curr_640_qooxdoo_1/best\n",
      "Loaded model from directory ./storage//tmp/finetuned/curr_640_qooxdoo_1/best\n",
      "cuda:0\n",
      "Testing has started\n",
      "Number of testing samples:  115\n",
      "score average: 0.5391304347826087 samples_count: 115\n",
      "result : ./storage//testing/11/per-repo/t5-small_test_qooxdoo_11-02-2022_00-17-06\n",
      "end time:  00:17:33\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "result = os.system(f'python hf_transformers/tfix_testing.py --load-model {tuned_model_dir} -bs 16 --model-name t5-small -d repo-based-included -r {repo}')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a28a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(tuned_model_dir)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bebecc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460a2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53aed71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7504660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c597ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1ca15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330dafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53729a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942a5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c308b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e1495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
